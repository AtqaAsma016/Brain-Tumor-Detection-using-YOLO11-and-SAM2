# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Kl04NsGxIPA7yWPG7sWH0e5kB9MF19dr
"""

pip install ultralytics

from google.colab import files
uploaded = files.upload()

import zipfile
import os

# Unzip the uploaded file (adjust name if needed)
with zipfile.ZipFile("Tumor Detection.v8i.yolov11.zip", 'r') as zip_ref:
    zip_ref.extractall("/content/TumorDetection")

# Now your dataset is in /content/TumorDetection

from ultralytics import YOLO

model = YOLO("yolo11n.pt")

train_results = model.train(
    data = "/content/TumorDetection/data.yaml",
    epochs = 20,
    imgsz = 640,
    device = 0,
)

from google.colab import files
from pathlib import Path

# List all training runs
!ls runs/detect/
# Navigate to the latest run
!ls runs/detect/train/weights/best.pt

import os

# Define paths
tumor_detection_path = "/content/TumorDetection"  # Adjust if your path is different
test_images_path = os.path.join(tumor_detection_path, "test_images")

# Create the folder if it doesn't exist
os.makedirs(test_images_path, exist_ok=True)

print(f"Created folder: {test_images_path}")

from google.colab import files
import os

# Upload images (opens a file dialog)
uploaded = files.upload()  # Select one or multiple images from your local machine

# Define paths
tumor_detection_path = "/content/TumorDetection"  # Adjust if needed
test_images_path = os.path.join(tumor_detection_path, "test_images")

# Create the folder if it doesn't exist
os.makedirs(test_images_path, exist_ok=True)

# Move uploaded files to the folder
for filename in uploaded.keys():
    os.rename(filename, os.path.join(test_images_path, filename))

print(f"Images moved to: {test_images_path}")
print("Uploaded files:", os.listdir(test_images_path))

from ultralytics import YOLO

# Load your trained model
model = YOLO("runs/detect/train/weights/best.pt")  # Adjust path if needed

# Run inference on all images in test_images
results = model.predict(
    source=test_images_path,  # Uses all images in the folder
    save=True,
    conf=0.5  # Confidence threshold
)

# Display the first result (optional)
results[0].show()

from ultralytics import YOLO  # Corrected import (not "VOLO")

# Load your trained model
model = YOLO("runs/detect/train/weights/best.pt")  # Fixed path (no "run:/")

# Run inference on an image
results = model.predict("/content/TumorDetection/test_images/meningioma_527_jpg.rf.e6e1894c4c938833c4c210580dd04ebc.jpg")  # Use .predict() instead of direct call

# Process results
for result in results:
    boxes = result.boxes  # Access detected bounding boxes
    print("Detected boxes:")
    print(f"  - Coordinates (xyxy): {boxes.xyxy}")  # [x1, y1, x2, y2] format
    print(f"  - Confidence scores: {boxes.conf}")
    print(f"  - Class IDs: {boxes.cls}")

    # Optional: Visualize results
    result.show()  # Display image with bounding boxes
    result.save("output.jpg")  # Save output image

# Core dependencies
!pip install torch torchvision torchaudio
!pip install opencv-python-headless pycocotools matplotlib

# Install Segment Anything from source (most reliable method)
!pip install git+https://github.com/facebookresearch/segment-anything.git

# For visualization (optional)
!pip install supervision

!wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth

import sys
from ultralytics import YOLO
import torch
import cv2
import numpy as np

# Verify SAM installation
try:
    from segment_anything import sam_model_registry, SamPredictor
except ModuleNotFoundError:
    print("SAM not installed! Installing now...")
    !pip install git+https://github.com/facebookresearch/segment-anything.git
    from segment_anything import sam_model_registry, SamPredictor

# 1. Load YOLO model
try:
    yolo_model = YOLO("runs/detect/train/weights/best.pt")
    print("✔ YOLO model loaded successfully")
except Exception as e:
    print(f"Error loading YOLO model: {e}")
    sys.exit()

# 2. Run YOLO inference
img_path = "/content/TumorDetection/test_images/meningioma_527_jpg.rf.e6e1894c4c938833c4c210580dd04ebc.jpg"
try:
    results = yolo_model.predict(img_path)
    print("✔ YOLO prediction complete")
except Exception as e:
    print(f"YOLO prediction failed: {e}")
    sys.exit()

# 3. Setup SAM
sam_checkpoint = "sam_vit_h_4b8939.pth"
model_type = "vit_h"
device = "cuda" if torch.cuda.is_available() else "cpu"

try:
    sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)
    sam.to(device=device)
    predictor = SamPredictor(sam)
    print("✔ SAM model loaded successfully")
except Exception as e:
    print(f"SAM initialization failed: {e}")
    print("Did you download the model weights?")
    print(f"Expected file: {sam_checkpoint}")
    sys.exit()

# 4. Process results
for result in results:
    try:
        # Get bounding boxes
        boxes = result.boxes.xyxy.cpu().numpy()

        if len(boxes) > 0:
            # Load and prepare image
            image = cv2.imread(img_path)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

            # SAM prediction
            predictor.set_image(image)
            input_boxes = torch.tensor(boxes, device=device)
            transformed_boxes = predictor.transform.apply_boxes_torch(input_boxes, image.shape[:2])

            masks, _, _ = predictor.predict_torch(
                point_coords=None,
                point_labels=None,
                boxes=transformed_boxes,
                multimask_output=False,
            )

            # Visualize results
            for mask in masks:
                mask = mask.cpu().numpy()[0]
                color = np.array([30/255, 144/255, 255/255, 0.6])
                h, w = mask.shape[-2:]
                mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)
                image = cv2.addWeighted(image, 1.0, (mask_image * 255).astype(np.uint8), 0.6, 0)

            # Save result
            output_path = "output.jpg"
            cv2.imwrite(output_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))
            print(f"✔ Results saved to {output_path}")

    except Exception as e:
        print(f"Error processing results: {e}")